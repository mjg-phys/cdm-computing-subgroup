{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjg-phys/cdm-computing-subgroup/blob/main/CDM_particleImageClassifier_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGEdpY6AAufo"
      },
      "source": [
        "# Particle image classifier\n",
        "\n",
        "This notebook is originally from the SLAC Summer Institute and was one of the challenges of the intensity frontier. For more details see this [page](https://github.com/makagan/SSI_Projects/tree/main/if_projects).\n",
        "\n",
        "This is a particle image classification problem. Four type of particles (electron, photon, muon, and proton) are simulated in liquid argon medium and the 2D projections of their 3D energy deposition patterns (\"trajectories\") are recorded. The challenge is to develop a classifier algorithm that identify which of four types is present in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2Snw358Aufp"
      },
      "source": [
        "## Setting up\n",
        "\n",
        "Pull the scripts for the project and download the data files. You only need to do this once per machine/instance you are using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UyxenE9xAufp",
        "outputId": "1fb68beb-0ac2-4482-e6e2-a64a4abddfb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/drinkingkazu/ssi_if\n",
            "  Cloning https://github.com/drinkingkazu/ssi_if to /tmp/pip-req-build-2gpvkidc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/drinkingkazu/ssi_if /tmp/pip-req-build-2gpvkidc\n",
            "  Resolved https://github.com/drinkingkazu/ssi_if to commit af38e2ce0730ec5a3091a849bee9e8e53d58042d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (5.1.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (0.6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (3.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (2.2.1+cu121)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (2.5.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (5.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->iftools==0.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->iftools==0.1) (2.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->iftools==0.1) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->iftools==0.1) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->iftools==0.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown->iftools==0.1) (4.66.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py->iftools==0.1) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->iftools==0.1) (8.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->iftools==0.1) (12.4.127)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->iftools==0.1) (1.11.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric->iftools==0.1) (3.9.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->iftools==0.1) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->iftools==0.1) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->iftools==0.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->iftools==0.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->iftools==0.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->iftools==0.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->iftools==0.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->iftools==0.1) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->iftools==0.1) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->iftools==0.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (1.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->iftools==0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->iftools==0.1) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->iftools==0.1) (1.3.0)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=130Lm_4K2cCclnmOEZlVIBKKPkJUn3k3f\n",
            "From (redirected): https://drive.google.com/uc?id=130Lm_4K2cCclnmOEZlVIBKKPkJUn3k3f&confirm=t&uuid=e3683d8c-d93f-4cc0-8c1a-f25ffca1acc7\n",
            "To: /content/if-image-train.h5\n",
            "100% 550M/550M [00:02<00:00, 237MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1L2yjBkzL3Ruaf8HuaMDR5PC9nETG5t_i\n",
            "From (redirected): https://drive.google.com/uc?id=1L2yjBkzL3Ruaf8HuaMDR5PC9nETG5t_i&confirm=t&uuid=83b50057-b9e3-47c6-b6ac-6fbf25338f17\n",
            "To: /content/if-image-test.h5\n",
            "100% 138M/138M [00:00<00:00, 258MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/drinkingkazu/ssi_if\n",
        "! download_if_dataset.py --challenge=image --flavor=train\n",
        "! download_if_dataset.py --challenge=image --flavor=test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV7OA8nZAufp"
      },
      "source": [
        "and setting some global configurations including seeds (change as u see fit!) for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dV8tqrEbAufr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "004dc61e-1441-4bbf-d412-71b66ddb640d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "context has already been set",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c6d736f6aa6f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/context.py\u001b[0m in \u001b[0;36mset_start_method\u001b[0;34m(self, method, force)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'context has already been set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actual_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: context has already been set"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "mpl.rcParams['figure.figsize'] = [8, 6]\n",
        "mpl.rcParams['font.size'] = 16\n",
        "mpl.rcParams['axes.grid'] = True\n",
        "\n",
        "import torch\n",
        "torch.multiprocessing.set_start_method('spawn')\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "import numpy as np\n",
        "SEED=12345\n",
        "_=np.random.seed(SEED)\n",
        "_=torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBYrgciFAufr"
      },
      "source": [
        "## Data file contents\n",
        "\n",
        "* A data file with 400,000 images for training: `train.h5`\n",
        "  * ... which include 100,000 images per particle type\n",
        "* A data file with 100,000 images for testing: `test.h5`\n",
        "  * ... which include 25,000 images per particle type\n",
        "\n",
        "These files are `HDF5` files and can be opened using `h5py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0i78jibAufr"
      },
      "outputs": [],
      "source": [
        "import h5py as h5\n",
        "datapath='if-image-train.h5'\n",
        "\n",
        "# Open a file in 'r'ead mode.\n",
        "f=h5.File(datapath,mode='r',swmr=True)\n",
        "\n",
        "# List items in the file\n",
        "for key in f.keys():\n",
        "    print('dataset',key,'... type',f[key].dtype,'... shape',f[key].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzVcSgj1Aufs"
      },
      "source": [
        "... and let's visualize one image for fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8QxPHnFAufs"
      },
      "outputs": [],
      "source": [
        "entry = 1\n",
        "\n",
        "print('PDG code',f['pdg'][entry])\n",
        "plt.imshow(f['image'][entry],origin='lower')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh3FS_N2Aufs"
      },
      "source": [
        "PDG code 13 means muon (if you are unfamiliar, \"PDG code\" is a signed integer as a unique identifier of a particle. See [this documentation](https://pdg.lbl.gov/2006/reviews/pdf-files/montecarlo-web.pdf) for more details.)\n",
        "\n",
        "Let's don't forget to close the file :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBfXqTaeAufs"
      },
      "outputs": [],
      "source": [
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6N7aGrpAufs"
      },
      "source": [
        "## Particle Image `Dataset` and `DataLoader`\n",
        "\n",
        "We prepared a simple torch `Dataset` implementation for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sHrY6tdAufs"
      },
      "outputs": [],
      "source": [
        "from iftool.image_challenge import ParticleImage2D\n",
        "train_data = ParticleImage2D(data_files=[datapath])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feNRB-73Auft"
      },
      "source": [
        "The dataset is index-accessible and produce a dictionary with four keys\n",
        "* `data` ... 2D image of a particle (192x192 pixels)\n",
        "* `pdg` ... PDG code of a particle. Should be [11,13,22,2212] = [electron,muon,photon,proton]\n",
        "* `label` ... an integer label for classification\n",
        "* `index` ... an index of the data entry from an input file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl7IM61IAuft"
      },
      "outputs": [],
      "source": [
        "print('Size of dataset',len(train_data))\n",
        "\n",
        "# 0  - 13, muon\n",
        "# 3  - 11 , electron\n",
        "# 12 - 22 , photon\n",
        "# 4  - 2212, proton\n",
        "\n",
        "all_types = [0,3,12,4]\n",
        "\n",
        "# The data instance is a dictionary\n",
        "# Visualize the image\n",
        "for i in all_types:\n",
        "  data = train_data[i]\n",
        "  print('PDG code %d ... label %d \\n' % (data['pdg'],data['label']))\n",
        "  plt.imshow(data['data'],origin='lower')\n",
        "  print(data['data'].size())\n",
        "  plt.show()\n",
        "\n",
        "print('List of keys in a data element',data.keys(),'\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hp4PrWzAuft"
      },
      "source": [
        "Create a `DataLoader` instance in a usual way except we give a specifically designed collate function to handle a dictionary style data instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVvwgsI3Auft"
      },
      "outputs": [],
      "source": [
        "train_start = 0.0\n",
        "train_end = 0.1\n",
        "val_start = 0.1\n",
        "val_end = 0.15\n",
        "test_start = 0.15\n",
        "test_end = 0.20\n",
        "\n",
        "train_data = ParticleImage2D(data_files = [datapath],\n",
        "                             start = train_start, # start of the dataset fraction to use. 0.0 = use from 1st entry\n",
        "                             end   = train_end, # end of the dataset fraction to use. 1.0 = use up the last entry\n",
        "                            )\n",
        "val_data = ParticleImage2D(data_files = [datapath],\n",
        "                             start = val_start, # start of the dataset fraction to use. 0.0 = use from 1st entry\n",
        "                             end   = val_end, # end of the dataset fraction to use. 1.0 = use up the last entry\n",
        "                            )\n",
        "\n",
        "\n",
        "# We use a specifically designed \"collate\" function to create a batch data\n",
        "from iftool.image_challenge import collate\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_data,\n",
        "                          collate_fn  = collate,\n",
        "                          shuffle     = True,\n",
        "                          num_workers = 2,\n",
        "                          batch_size  = 100\n",
        "                         )\n",
        "\n",
        "val_loader = DataLoader(val_data,\n",
        "                          collate_fn  = collate,\n",
        "                          shuffle     = True,\n",
        "                          num_workers = 2,\n",
        "                          batch_size  = 100\n",
        "                         )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jzSAQDhAuft"
      },
      "source": [
        "Let's measure the speed of the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqMAEYcOAuft"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "tstart=time.time()\n",
        "num_iter=100\n",
        "ctr=num_iter\n",
        "for batch in train_loader:\n",
        "    ctr -=100\n",
        "    if ctr <= 0: break\n",
        "print((time.time()-tstart)/num_iter,'[s/iteration]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4pRK4eaAufu"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Here are open-ended challenge project for an image classification.\n",
        "\n",
        "* Design a machine learning algorithm for performing image classification task. Report the performance (speed, memory, and classification accuracy) you achieved on the test set (remember, use the test set to only benchmark, don't use it for hyper parameter tuning nor training the model!). You might just train very long time, modify the network architecture, or come up with a better training strategy. Let us know what you tried and found!\n",
        "\n",
        "If you want more guidance, you could try the steps below. But stay open minded and try what you think interesting!\n",
        "\n",
        "1. Write a python script that trains your model for 70,000 steps using 90% of training sample. Store the network weights every 2500 steps.\n",
        "\n",
        "2. Use 10% of training sample as a validation set. Quantify the performance (loss and accuracy) on the stored weights (at every 2500 steps) by running the network inference on the full validation set. You can do this after training is over, or while you are training the network.\n",
        "\n",
        "3. Look for features in mistakes made by the network. When is it hard for the network to identify a particle? Can you engineer variables to guide this search (e.g. number of pixel count per image v.s. softmax score, average pixel value, etc.)?\n",
        "\n",
        "4. Play with the network architecture. For instance, if you designed a CNN, could you implement a residual connection? How does that affect the speed and performance of your network?\n",
        "\n",
        "5. Can we speed-up the network (training time and/or inference time)? What's the trade-off with its performance on the task (i.e. accuracy)?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example: Dense Neural Network\n",
        "\n",
        "To help get you started, we will go through an example using a Dense Neural Network. In the context of image data, this does not make the most sense, but we will see that it is still able to classify. First, we will make a DenseNN class:"
      ],
      "metadata": {
        "id": "mShkHNXPcSPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the neural network architecture\n",
        "class DenseNN(nn.Module):\n",
        "    def __init__(self,inputNum):\n",
        "        super(DenseNN, self).__init__()\n",
        "        self.inputNum=inputNum\n",
        "        self.fc1 = nn.Linear(in_features=inputNum, out_features=16)  # Input layer\n",
        "        self.fc2 = nn.Linear(in_features=16, out_features=16)     # Hidden layer\n",
        "        self.fc3 = nn.Linear(in_features=16, out_features=16)     # Hidden layer\n",
        "        self.fc4 = nn.Linear(in_features=16, out_features=4)     # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.inputNum)   # Flatten the input\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "I1M97K_0OMen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "flattened_data = data['data'].flatten()\n",
        "n = flattened_data.size()[0]\n",
        "model = DenseNN(inputNum=n)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"In epoch: \", epoch)\n",
        "  running_loss_train = []\n",
        "  running_loss_val = []\n",
        "  index=  0\n",
        "  for batch in train_loader:\n",
        "      index = index+1\n",
        "      inputs =  batch['data']\n",
        "      labels = batch['label']\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Backward pass and optimize\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss_train.append(loss.item())\n",
        "      if index % 100 == 99:    # Print every 100 mini-batches\n",
        "        print(\"batch: \", index, \" loss = \" , np.mean(np.asarray(running_loss_train)))\n",
        "\n",
        "  print(\"End train epoch, mean loss: \", np.mean(np.asarray(running_loss_train)))\n",
        "  index = 0\n",
        "  for batch in val_loader:\n",
        "      index = index+1\n",
        "      inputs =  batch['data']\n",
        "      labels = batch['label']\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      running_loss_val.append(loss.item())\n",
        "      if index % 100 == 99:    # Print every 100 mini-batches\n",
        "        print(\"batch: \", index, \" loss = \" , np.mean(np.asarray(running_loss_val)))\n",
        "\n",
        "  print(\"End val epoch, mean loss: \", np.mean(np.asarray(running_loss_val)))\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "id": "FvEY0DbvmCti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to see how well our model is performing, we can look at a test dataset...\n",
        "\n",
        "test_data = ParticleImage2D(data_files = [datapath],\n",
        "                             start = test_start, # start of the dataset fraction to use. 0.0 = use from 1st entry\n",
        "                             end   = test_end, # end of the dataset fraction to use. 1.0 = use up the last entry\n",
        "                            )\n",
        "\n",
        "test_loader = DataLoader(test_data,\n",
        "                          collate_fn  = collate,\n",
        "                          shuffle     = True,\n",
        "                          num_workers = 2,\n",
        "                          batch_size  = 1000\n",
        "                         )"
      ],
      "metadata": {
        "id": "HwfsjojmSthN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "\n",
        "y_target = []\n",
        "y_pred = []\n",
        "for batch in test_loader:\n",
        "      inputs =  batch['data']\n",
        "      labels = batch['label']\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      print(loss)\n",
        "      numpy_array = outputs.detach().numpy()\n",
        "      y_target.extend(labels.numpy())\n",
        "      y_pred.extend(numpy_array)\n",
        "\n",
        "\n",
        "y_target = np.array(y_target)  # Example true labels\n",
        "y_pred = np.array(y_pred)  # Example predicted probabilities\n"
      ],
      "metadata": {
        "id": "XsCxsKoZcffO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "particleTypes = [\"muon\", \"electron\", \"photon\", \"proton\"]\n",
        "def plot_roc_curve(y_true, y_pred_prob):\n",
        "    # Binarize the labels\n",
        "    y_true_binarized = label_binarize(y_true, classes=[0, 1, 2, 3])\n",
        "\n",
        "    column_sums = np.sum(y_true_binarized, axis=0)\n",
        "    print(column_sums)\n",
        "    print(y_true_binarized)\n",
        "    print(y_pred_prob)\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(4):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_prob[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Plot ROC curves\n",
        "    plt.figure()\n",
        "    colors = ['blue', 'red', 'green', 'orange']\n",
        "    for i, color in zip(range(4), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                 label='ROC curve of {0} (area = {1:0.2f})'\n",
        "                 ''.format(particleTypes[i], roc_auc[i]))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve for 4-class Classification')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "# Replace y_true and y_pred_prob with your actual labels and predicted probabilities\n",
        "y_target = np.array(y_target)  # Example true labels\n",
        "y_pred = np.array(y_pred)  # Example predicted probabilities\n",
        "plot_roc_curve(y_target, y_pred)\n"
      ],
      "metadata": {
        "id": "fgH-01eSehOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Work:\n",
        "This is our baseline results. It is up to you to investigate other models.\n",
        "\n",
        "1) CNN: There is an example of a CNN below, with 3 convolution layers into a single fully connected layer. This is loosely based off of AlexNet. You should be able to use this instead of the DenseNN.\n",
        "\n",
        "2) GNN: Looking at the images, the data is quite sparse. It might be a good idea to represent the data as a graph. Instead of using ParticleImage2D, we can use ParticleImageGraph to represent the cells of the LAr that have an energy deposition. We can then use a graph neural network as our model.\n",
        "\n",
        "Try both of these to see results. Try your own! Honestly, ChatGPT helped make the CNN and GNN below, maybe you can use it to make a transformer!\n"
      ],
      "metadata": {
        "id": "DHvCpJ0MjXUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Base:"
      ],
      "metadata": {
        "id": "1o5SKBLV9S7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=2, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=2, out_channels=4, kernel_size=2, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
        "        self.conv3 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=2, stride=1, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer\n",
        "        self.fc = nn.Linear(in_features=8 * 24 * 24, out_features=4)  # Adjusted input size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool1(x)  # Max pooling\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool2(x)  # Max pooling\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = self.pool3(x)  # Max pooling\n",
        "        x = x.view(-1, 8 * 24 * 24)  # Adjusted input size\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN()\n"
      ],
      "metadata": {
        "id": "q2AQJooWudO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN Base:\n",
        "\n",
        "Since we need our data in Graph Form, there is now a class called \"ParticleImageGraph\" that takes our image of the particle and translates it to a graph, where the nodes are the indivudal pixels of the image, and they are connected if they are next to one another in the original image. You will need to use this rather than the ParticleImage2D class form before"
      ],
      "metadata": {
        "id": "mdJUg0BL9VfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import h5py\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from skimage.transform import resize\n",
        "\n",
        "class ParticleImageGraph(Dataset):\n",
        "\n",
        "    def __init__(self, data_files, start=0.0, end=1.0, normalize=None, threshold=0.1):\n",
        "\n",
        "        self._files = [f if f.startswith('/') else os.path.join(os.getcwd(), f) for f in data_files]\n",
        "        for f in self._files:\n",
        "            if os.path.isfile(f): continue\n",
        "            sys.stderr.write('File not found:%s\\n' % f)\n",
        "            raise FileNotFoundError\n",
        "\n",
        "        if start < 0. or start > 1.:\n",
        "            print('start must take a value between 0.0 and 1.0')\n",
        "            raise ValueError\n",
        "\n",
        "        if end < 0. or end > 1.:\n",
        "            print('end must take a value between 0.0 and 1.0')\n",
        "            raise ValueError\n",
        "\n",
        "        if end <= start:\n",
        "            print('end must be larger than start')\n",
        "            raise ValueError\n",
        "\n",
        "        self._file_handles = [None] * len(self._files)\n",
        "        self._entry_to_file_index  = []\n",
        "        self._entry_to_data_index = []\n",
        "        self._shape = None\n",
        "        self.classes = []\n",
        "        self._normalize = normalize\n",
        "        self.threshold = threshold\n",
        "        for file_index, file_name in enumerate(self._files):\n",
        "            f = h5py.File(file_name, mode='r', swmr=True)\n",
        "            data_size = f['image'].shape[0]\n",
        "            if not len(f['pdg']) == data_size:\n",
        "                print(f['image'].shape, len(f['pdg']))\n",
        "                raise Exception\n",
        "            self._entry_to_file_index += [file_index] * data_size\n",
        "            self._entry_to_data_index += range(data_size)\n",
        "            self.classes += [pdg for pdg in np.unique(f['pdg'])]\n",
        "            print(self.classes)\n",
        "            f.close()\n",
        "\n",
        "        self.classes = list(np.unique(self.classes))\n",
        "        self._start  = int(len(self._entry_to_file_index) * start)\n",
        "        self._length = int(len(self._entry_to_file_index) * end) - self._start\n",
        "\n",
        "    def __del__(self):\n",
        "        for i in range(len(self._file_handles)):\n",
        "            if self._file_handles[i]:\n",
        "                self._file_handles[i].close()\n",
        "                self._file_handles[i] = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_index  = self._entry_to_file_index[self._start + idx]\n",
        "        entry_index = self._entry_to_data_index[self._start + idx]\n",
        "        if self._file_handles[file_index] is None:\n",
        "            self._file_handles[file_index] = h5py.File(self._files[file_index], mode='r', swmr=True)\n",
        "\n",
        "        fh = self._file_handles[file_index]\n",
        "\n",
        "        data = torch.Tensor(fh['image'][entry_index])\n",
        "        if self._normalize:\n",
        "            data = (data - self._normalize[0]) / self._normalize[1]\n",
        "\n",
        "        active_pixels = data.numpy() > self.threshold\n",
        "        height, width = active_pixels.shape\n",
        "        node_features = []\n",
        "        edge_index = []\n",
        "\n",
        "        pos_to_idx = {}\n",
        "        idx = 0\n",
        "        for x in range(height):\n",
        "            for y in range(width):\n",
        "                if active_pixels[x, y]:\n",
        "                    pos_to_idx[x, y] = idx\n",
        "                    node_features.append([data[x, y].item()])\n",
        "                    idx += 1\n",
        "\n",
        "        def add_edges(x, y):\n",
        "            if x > 0 and active_pixels[x-1, y]:\n",
        "                edge_index.append([pos_to_idx[x, y], pos_to_idx[x-1, y]])\n",
        "            if x < height-1 and active_pixels[x+1, y]:\n",
        "                edge_index.append([pos_to_idx[x, y], pos_to_idx[x+1, y]])\n",
        "            if y > 0 and active_pixels[x, y-1]:\n",
        "                edge_index.append([pos_to_idx[x, y], pos_to_idx[x, y-1]])\n",
        "            if y < width-1 and active_pixels[x, y+1]:\n",
        "                edge_index.append([pos_to_idx[x, y], pos_to_idx[x, y+1]])\n",
        "\n",
        "        for x in range(height):\n",
        "            for y in range(width):\n",
        "                if active_pixels[x, y]:\n",
        "                    add_edges(x, y)\n",
        "\n",
        "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
        "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        label, pdg = None, None\n",
        "        if 'pdg' in fh:\n",
        "            pdg = fh['pdg'][entry_index]\n",
        "            label = self.classes.index(pdg)\n",
        "\n",
        "        return Data(x=node_features, edge_index=edge_index, y=torch.tensor([label]))\n",
        "\n",
        "def collate(batch):\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "PIfiZHe-h7TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc = torch.nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)  # Global pooling to get graph-level representation\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B7VkOe_wkEvp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}